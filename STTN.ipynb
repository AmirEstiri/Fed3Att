{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STTN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBcDTdxiEiCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a014c34-44ae-4190-c758-8db409e41cc6"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiZ0P06bT9C0"
      },
      "source": [
        "B = 8\n",
        "H = 10 # Grid height\n",
        "W = 10 # Grid width\n",
        "N = H*W # Nodes in grpah\n",
        "M = 15 # previous time steps\n",
        "T = 5 # future time steps\n",
        "TIME_STEP = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3ONY632vkGa"
      },
      "source": [
        "def normalize(vec):\n",
        "    return (vec-min(vec))/(max(vec)-min(vec))\n",
        "\n",
        "df = pd.read_csv('gdrive/MyDrive/trace/trace_avg.csv')\n",
        "MAX_COST = 200\n",
        "df = df[df['Cost'] < MAX_COST]\n",
        "df['Cost'] = df['Cost'] / MAX_COST\n",
        "df['Long'] = normalize(df['Long'])\n",
        "df['Lat'] = normalize(df['Lat'])\n",
        "\n",
        "df['TimeStep'] = round(df['TimeSec'] / TIME_STEP)\n",
        "df['LongStep'] = round(df['Long'] * (H-1))\n",
        "df['LatStep'] = round(df['Lat'] * (W-1))\n",
        "df['GraphNode'] = (df['LongStep']-1) * W + df['LatStep']\n",
        "df = df.groupby(['GraphNode', 'TimeStep'])['Cost'].mean().reset_index()\n",
        "\n",
        "############################################################\n",
        "\n",
        "times = np.unique(df['TimeStep'])\n",
        "dataset = []\n",
        "\n",
        "for t in times:\n",
        "    grid = np.ones((H*W, 1)) * -1\n",
        "    df_t = df[df['TimeStep'] == t]\n",
        "    for index, row in df_t.iterrows():\n",
        "        lat_step = row['GraphNode'] % W\n",
        "        long_step = (row['GraphNode'] - lat_step) / W + 1\n",
        "        index = int(W*(long_step-1)+lat_step)\n",
        "        grid[index] = row['Cost']\n",
        "    dataset.append(grid)\n",
        "dataset = np.array(dataset)\n",
        "del df\n",
        "\n",
        "############################################################\n",
        "\n",
        "indf = []\n",
        "outdf = []\n",
        "\n",
        "for i in range(len(dataset)-M-T-1):\n",
        "    indf.append(dataset[i:i+M])\n",
        "    outdf.append(dataset[i+M:i+M+T])\n",
        "\n",
        "del dataset\n",
        "\n",
        "L = len(indf)\n",
        "cutoff = L-L%B\n",
        "indf = np.swapaxes(np.array(indf), 1, 2)[:cutoff]\n",
        "outdf = np.swapaxes(np.array(outdf), 1, 2)[:cutoff]\n",
        "\n",
        "indf = np.reshape(indf, (-1, B, indf.shape[1], indf.shape[2]))\n",
        "outdf = np.reshape(outdf, (-1, B, outdf.shape[1], outdf.shape[2]))\n",
        "\n",
        "l = int(0.9*len(indf))\n",
        "indf_train = indf[:l]\n",
        "outdf_train = outdf[:l]\n",
        "indf_test = indf[l:]\n",
        "outdf_test = outdf[l:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHrlBzdcrsm1"
      },
      "source": [
        " def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "    d_A = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(d_A)\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "def create_mask(seq):\n",
        "    x = tf.cast(tf.math.equal(seq, -1.0), tf.float32)\n",
        "    x_ = tf.transpose(x, perm=[0, 2, 1])\n",
        "    t_mask = tf.matmul(x[:, :, :, np.newaxis], x[:, :, np.newaxis, :])\n",
        "    s_mask = tf.matmul(x_[:, :, :, np.newaxis], x_[:, :, np.newaxis, :])\n",
        "    return s_mask, t_mask\n",
        "\n",
        "\n",
        "def loss_function(real, pred, loss_func):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, -1.0))\n",
        "    if loss_func == 'MSE':\n",
        "        loss = tf.square(tf.cast(real, dtype=tf.float32) - tf.cast(pred, dtype=tf.float32))\n",
        "    elif loss_func == 'MAE':\n",
        "        loss = tf.abs(tf.cast(real, dtype=tf.float32) - tf.cast(pred, dtype=tf.float32))\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def point_wise_feed_forward_network(d_G):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(d_G, activation='relu'),\n",
        "        # tf.keras.layers.Dense(d_G, activation='relu'),\n",
        "        # tf.keras.layers.Dense(d_G, activation='relu')\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14bAihM4qNlY"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_A, d_G):\n",
        "        super(Attention, self).__init__()\n",
        "        self.d_G = d_G\n",
        "        self.d_A = d_A\n",
        "        self.wq = tf.keras.layers.Dense(d_A)\n",
        "        self.wk = tf.keras.layers.Dense(d_A)\n",
        "        self.wv = tf.keras.layers.Dense(d_G)\n",
        "        self.dense = tf.keras.layers.Dense(d_G)\n",
        "\n",
        "    def call(self, q, k, v, mask):\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        output = self.dense(scaled_attention)\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "class FeatureAggregation(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_G):\n",
        "        super(FeatureAggregation, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(d_G, (1,1))\n",
        "\n",
        "    def call(self, x):\n",
        "        x = x[:, :, :, tf.newaxis]\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class DynamicSpatialLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_A, d_G):\n",
        "        super(DynamicSpatialLayer, self).__init__()\n",
        "        self.att = Attention(d_A, d_G)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        x_ = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        ds_out, ds_att = self.att(x_, x_, x_, mask)\n",
        "        ds_out = tf.transpose(ds_out, perm=[0, 2, 1, 3])\n",
        "        return ds_out + x, ds_att\n",
        "\n",
        "\n",
        "\n",
        "class SpatialLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_A, d_G):\n",
        "        super(SpatialLayer, self).__init__()\n",
        "        self.d_A = d_A\n",
        "        self.d_G = d_G\n",
        "        self.ds_layer = DynamicSpatialLayer(d_A, d_G)\n",
        "        self.feed_forward_network = point_wise_feed_forward_network(d_G)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        ds_out, ds_att = self.ds_layer(x, mask)\n",
        "        out = self.feed_forward_network(ds_out)\n",
        "        return out + x, None, ds_att\n",
        "\n",
        "\n",
        "\n",
        "class TemporalLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_A, d_G):\n",
        "        super(TemporalLayer, self).__init__()\n",
        "        self.att = Attention(d_A, d_G)\n",
        "        self.feed_forward_network = point_wise_feed_forward_network(d_G)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        t_out, t_att = self.att(x, x, x, mask)\n",
        "        out = self.feed_forward_network(t_out)\n",
        "        return out + x, t_att\n",
        "\n",
        "\n",
        "\n",
        "class PredictionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, T):\n",
        "        super(PredictionLayer, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(T, activation='sigmoid')\n",
        "        self.conv1 = tf.keras.layers.Conv2D(10, (1,1))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(20, (1,1))\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = tf.reshape(x, (x.shape[0], x.shape[1], -1))\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpatioTemporalTransformer(tf.keras.Model):\n",
        "    def __init__(self, d_A, d_G, T):\n",
        "        super(SpatioTemporalTransformer, self).__init__()\n",
        "        self.feature_aggregation = FeatureAggregation(d_G)\n",
        "        self.spatial_transformer = SpatialLayer(d_A, d_G)\n",
        "        self.temporal_transformer = TemporalLayer(d_A, d_G)\n",
        "        self.prediction_layer = PredictionLayer(T)\n",
        "\n",
        "    def call(self, inp, s_mask, t_mask):\n",
        "        x = self.feature_aggregation(inp)\n",
        "        s_out, ss_att, ds_att = self.spatial_transformer(x, s_mask)\n",
        "        t_out, t_att = self.temporal_transformer(s_out, t_mask)\n",
        "        out = self.prediction_layer(t_out)\n",
        "        return out, ss_att, ds_att, t_att\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK39kssUt9nY"
      },
      "source": [
        "d_A = 64\n",
        "d_G = 64\n",
        "\n",
        "sttn = SpatioTemporalTransformer(d_A, d_G, T)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    \n",
        "    s_mask, t_mask = create_mask(inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = sttn(inp, s_mask, t_mask)[0]\n",
        "        loss = loss_function(tar, pred, 'MSE')\n",
        "\n",
        "    gradients = tape.gradient(loss, sttn.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, sttn.trainable_variables))\n",
        "    train_loss(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CYzf-TcTvJu",
        "outputId": "d197f7e8-2005-4abe-f71e-58f55398e5ac"
      },
      "source": [
        "EPOCHS = 20\n",
        "beginning = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "    for b in range(indf_train.shape[0]):\n",
        "        inp = indf_train[b]\n",
        "        tar = outdf_train[b]\n",
        "        train_step(inp, tar)\n",
        "        if b % 10 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {b} Loss {train_loss.result():.4f}')   \n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f}')\n",
        "print(f'Total time: {time.time() - beginning:.2f} secs\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1234\n",
            "Epoch 1 Batch 10 Loss 0.1047\n",
            "Epoch 1 Batch 20 Loss 0.0954\n",
            "Epoch 1 Batch 30 Loss 0.0775\n",
            "Epoch 1 Batch 40 Loss 0.0639\n",
            "Epoch 1 Batch 50 Loss 0.0566\n",
            "Epoch 1 Batch 60 Loss 0.0486\n",
            "Epoch 1 Batch 70 Loss 0.0449\n",
            "Epoch 1 Batch 80 Loss 0.0418\n",
            "Epoch 1 Batch 90 Loss 0.0379\n",
            "Epoch 1 Batch 100 Loss 0.0360\n",
            "Epoch 1 Batch 110 Loss 0.0334\n",
            "Epoch 1 Batch 120 Loss 0.0310\n",
            "Epoch 1 Batch 130 Loss 0.0290\n",
            "Epoch 1 Loss 0.0288\n",
            "Epoch 2 Batch 0 Loss 0.0286\n",
            "Epoch 2 Batch 10 Loss 0.0270\n",
            "Epoch 2 Batch 20 Loss 0.0254\n",
            "Epoch 2 Batch 30 Loss 0.0246\n",
            "Epoch 2 Batch 40 Loss 0.0234\n",
            "Epoch 2 Batch 50 Loss 0.0233\n",
            "Epoch 2 Batch 60 Loss 0.0224\n",
            "Epoch 2 Batch 70 Loss 0.0221\n",
            "Epoch 2 Batch 80 Loss 0.0220\n",
            "Epoch 2 Batch 90 Loss 0.0213\n",
            "Epoch 2 Batch 100 Loss 0.0212\n",
            "Epoch 2 Batch 110 Loss 0.0205\n",
            "Epoch 2 Batch 120 Loss 0.0199\n",
            "Epoch 2 Batch 130 Loss 0.0193\n",
            "Epoch 2 Loss 0.0192\n",
            "Epoch 3 Batch 0 Loss 0.0192\n",
            "Epoch 3 Batch 10 Loss 0.0187\n",
            "Epoch 3 Batch 20 Loss 0.0181\n",
            "Epoch 3 Batch 30 Loss 0.0179\n",
            "Epoch 3 Batch 40 Loss 0.0174\n",
            "Epoch 3 Batch 50 Loss 0.0175\n",
            "Epoch 3 Batch 60 Loss 0.0171\n",
            "Epoch 3 Batch 70 Loss 0.0171\n",
            "Epoch 3 Batch 80 Loss 0.0172\n",
            "Epoch 3 Batch 90 Loss 0.0169\n",
            "Epoch 3 Batch 100 Loss 0.0169\n",
            "Epoch 3 Batch 110 Loss 0.0166\n",
            "Epoch 3 Batch 120 Loss 0.0163\n",
            "Epoch 3 Batch 130 Loss 0.0160\n",
            "Epoch 3 Loss 0.0159\n",
            "Epoch 4 Batch 0 Loss 0.0159\n",
            "Epoch 4 Batch 10 Loss 0.0156\n",
            "Epoch 4 Batch 20 Loss 0.0153\n",
            "Epoch 4 Batch 30 Loss 0.0152\n",
            "Epoch 4 Batch 40 Loss 0.0150\n",
            "Epoch 4 Batch 50 Loss 0.0151\n",
            "Epoch 4 Batch 60 Loss 0.0148\n",
            "Epoch 4 Batch 70 Loss 0.0149\n",
            "Epoch 4 Batch 80 Loss 0.0150\n",
            "Epoch 4 Batch 90 Loss 0.0148\n",
            "Epoch 4 Batch 100 Loss 0.0148\n",
            "Epoch 4 Batch 110 Loss 0.0147\n",
            "Epoch 4 Batch 120 Loss 0.0144\n",
            "Epoch 4 Batch 130 Loss 0.0143\n",
            "Epoch 4 Loss 0.0142\n",
            "Epoch 5 Batch 0 Loss 0.0142\n",
            "Epoch 5 Batch 10 Loss 0.0140\n",
            "Epoch 5 Batch 20 Loss 0.0138\n",
            "Epoch 5 Batch 30 Loss 0.0138\n",
            "Epoch 5 Batch 40 Loss 0.0136\n",
            "Epoch 5 Batch 50 Loss 0.0137\n",
            "Epoch 5 Batch 60 Loss 0.0135\n",
            "Epoch 5 Batch 70 Loss 0.0136\n",
            "Epoch 5 Batch 80 Loss 0.0137\n",
            "Epoch 5 Batch 90 Loss 0.0135\n",
            "Epoch 5 Batch 100 Loss 0.0136\n",
            "Epoch 5 Batch 110 Loss 0.0135\n",
            "Epoch 5 Batch 120 Loss 0.0133\n",
            "Epoch 5 Batch 130 Loss 0.0132\n",
            "Epoch 5 Loss 0.0132\n",
            "Epoch 6 Batch 0 Loss 0.0132\n",
            "Epoch 6 Batch 10 Loss 0.0130\n",
            "Epoch 6 Batch 20 Loss 0.0129\n",
            "Epoch 6 Batch 30 Loss 0.0128\n",
            "Epoch 6 Batch 40 Loss 0.0127\n",
            "Epoch 6 Batch 50 Loss 0.0128\n",
            "Epoch 6 Batch 60 Loss 0.0127\n",
            "Epoch 6 Batch 70 Loss 0.0127\n",
            "Epoch 6 Batch 80 Loss 0.0128\n",
            "Epoch 6 Batch 90 Loss 0.0127\n",
            "Epoch 6 Batch 100 Loss 0.0127\n",
            "Epoch 6 Batch 110 Loss 0.0126\n",
            "Epoch 6 Batch 120 Loss 0.0125\n",
            "Epoch 6 Batch 130 Loss 0.0124\n",
            "Epoch 6 Loss 0.0124\n",
            "Epoch 7 Batch 0 Loss 0.0124\n",
            "Epoch 7 Batch 10 Loss 0.0123\n",
            "Epoch 7 Batch 20 Loss 0.0122\n",
            "Epoch 7 Batch 30 Loss 0.0122\n",
            "Epoch 7 Batch 40 Loss 0.0120\n",
            "Epoch 7 Batch 50 Loss 0.0121\n",
            "Epoch 7 Batch 60 Loss 0.0120\n",
            "Epoch 7 Batch 70 Loss 0.0120\n",
            "Epoch 7 Batch 80 Loss 0.0121\n",
            "Epoch 7 Batch 90 Loss 0.0120\n",
            "Epoch 7 Batch 100 Loss 0.0121\n",
            "Epoch 7 Batch 110 Loss 0.0120\n",
            "Epoch 7 Batch 120 Loss 0.0119\n",
            "Epoch 7 Batch 130 Loss 0.0118\n",
            "Epoch 7 Loss 0.0118\n",
            "Epoch 8 Batch 0 Loss 0.0118\n",
            "Epoch 8 Batch 10 Loss 0.0117\n",
            "Epoch 8 Batch 20 Loss 0.0116\n",
            "Epoch 8 Batch 30 Loss 0.0116\n",
            "Epoch 8 Batch 40 Loss 0.0115\n",
            "Epoch 8 Batch 50 Loss 0.0116\n",
            "Epoch 8 Batch 60 Loss 0.0115\n",
            "Epoch 8 Batch 70 Loss 0.0115\n",
            "Epoch 8 Batch 80 Loss 0.0116\n",
            "Epoch 8 Batch 90 Loss 0.0115\n",
            "Epoch 8 Batch 100 Loss 0.0116\n",
            "Epoch 8 Batch 110 Loss 0.0115\n",
            "Epoch 8 Batch 120 Loss 0.0114\n",
            "Epoch 8 Batch 130 Loss 0.0114\n",
            "Epoch 8 Loss 0.0114\n",
            "Epoch 9 Batch 0 Loss 0.0114\n",
            "Epoch 9 Batch 10 Loss 0.0113\n",
            "Epoch 9 Batch 20 Loss 0.0112\n",
            "Epoch 9 Batch 30 Loss 0.0112\n",
            "Epoch 9 Batch 40 Loss 0.0111\n",
            "Epoch 9 Batch 50 Loss 0.0112\n",
            "Epoch 9 Batch 60 Loss 0.0111\n",
            "Epoch 9 Batch 70 Loss 0.0111\n",
            "Epoch 9 Batch 80 Loss 0.0112\n",
            "Epoch 9 Batch 90 Loss 0.0111\n",
            "Epoch 9 Batch 100 Loss 0.0112\n",
            "Epoch 9 Batch 110 Loss 0.0111\n",
            "Epoch 9 Batch 120 Loss 0.0111\n",
            "Epoch 9 Batch 130 Loss 0.0110\n",
            "Epoch 9 Loss 0.0110\n",
            "Epoch 10 Batch 0 Loss 0.0110\n",
            "Epoch 10 Batch 10 Loss 0.0109\n",
            "Epoch 10 Batch 20 Loss 0.0109\n",
            "Epoch 10 Batch 30 Loss 0.0109\n",
            "Epoch 10 Batch 40 Loss 0.0108\n",
            "Epoch 10 Batch 50 Loss 0.0108\n",
            "Epoch 10 Batch 60 Loss 0.0108\n",
            "Epoch 10 Batch 70 Loss 0.0108\n",
            "Epoch 10 Batch 80 Loss 0.0108\n",
            "Epoch 10 Batch 90 Loss 0.0108\n",
            "Epoch 10 Batch 100 Loss 0.0108\n",
            "Epoch 10 Batch 110 Loss 0.0108\n",
            "Epoch 10 Batch 120 Loss 0.0107\n",
            "Epoch 10 Batch 130 Loss 0.0107\n",
            "Epoch 10 Loss 0.0107\n",
            "Epoch 11 Batch 0 Loss 0.0107\n",
            "Epoch 11 Batch 10 Loss 0.0106\n",
            "Epoch 11 Batch 20 Loss 0.0106\n",
            "Epoch 11 Batch 30 Loss 0.0106\n",
            "Epoch 11 Batch 40 Loss 0.0105\n",
            "Epoch 11 Batch 50 Loss 0.0105\n",
            "Epoch 11 Batch 60 Loss 0.0105\n",
            "Epoch 11 Batch 70 Loss 0.0105\n",
            "Epoch 11 Batch 80 Loss 0.0106\n",
            "Epoch 11 Batch 90 Loss 0.0105\n",
            "Epoch 11 Batch 100 Loss 0.0106\n",
            "Epoch 11 Batch 110 Loss 0.0105\n",
            "Epoch 11 Batch 120 Loss 0.0105\n",
            "Epoch 11 Batch 130 Loss 0.0104\n",
            "Epoch 11 Loss 0.0104\n",
            "Epoch 12 Batch 0 Loss 0.0104\n",
            "Epoch 12 Batch 10 Loss 0.0104\n",
            "Epoch 12 Batch 20 Loss 0.0103\n",
            "Epoch 12 Batch 30 Loss 0.0103\n",
            "Epoch 12 Batch 40 Loss 0.0103\n",
            "Epoch 12 Batch 50 Loss 0.0103\n",
            "Epoch 12 Batch 60 Loss 0.0103\n",
            "Epoch 12 Batch 70 Loss 0.0103\n",
            "Epoch 12 Batch 80 Loss 0.0103\n",
            "Epoch 12 Batch 90 Loss 0.0103\n",
            "Epoch 12 Batch 100 Loss 0.0103\n",
            "Epoch 12 Batch 110 Loss 0.0103\n",
            "Epoch 12 Batch 120 Loss 0.0103\n",
            "Epoch 12 Batch 130 Loss 0.0102\n",
            "Epoch 12 Loss 0.0102\n",
            "Epoch 13 Batch 0 Loss 0.0102\n",
            "Epoch 13 Batch 10 Loss 0.0102\n",
            "Epoch 13 Batch 20 Loss 0.0101\n",
            "Epoch 13 Batch 30 Loss 0.0101\n",
            "Epoch 13 Batch 40 Loss 0.0101\n",
            "Epoch 13 Batch 50 Loss 0.0101\n",
            "Epoch 13 Batch 60 Loss 0.0101\n",
            "Epoch 13 Batch 70 Loss 0.0101\n",
            "Epoch 13 Batch 80 Loss 0.0101\n",
            "Epoch 13 Batch 90 Loss 0.0101\n",
            "Epoch 13 Batch 100 Loss 0.0101\n",
            "Epoch 13 Batch 110 Loss 0.0101\n",
            "Epoch 13 Batch 120 Loss 0.0101\n",
            "Epoch 13 Batch 130 Loss 0.0100\n",
            "Epoch 13 Loss 0.0100\n",
            "Epoch 14 Batch 0 Loss 0.0100\n",
            "Epoch 14 Batch 10 Loss 0.0100\n",
            "Epoch 14 Batch 20 Loss 0.0100\n",
            "Epoch 14 Batch 30 Loss 0.0100\n",
            "Epoch 14 Batch 40 Loss 0.0099\n",
            "Epoch 14 Batch 50 Loss 0.0099\n",
            "Epoch 14 Batch 60 Loss 0.0099\n",
            "Epoch 14 Batch 70 Loss 0.0099\n",
            "Epoch 14 Batch 80 Loss 0.0100\n",
            "Epoch 14 Batch 90 Loss 0.0099\n",
            "Epoch 14 Batch 100 Loss 0.0100\n",
            "Epoch 14 Batch 110 Loss 0.0100\n",
            "Epoch 14 Batch 120 Loss 0.0099\n",
            "Epoch 14 Batch 130 Loss 0.0099\n",
            "Epoch 14 Loss 0.0099\n",
            "Epoch 15 Batch 0 Loss 0.0099\n",
            "Epoch 15 Batch 10 Loss 0.0099\n",
            "Epoch 15 Batch 20 Loss 0.0098\n",
            "Epoch 15 Batch 30 Loss 0.0098\n",
            "Epoch 15 Batch 40 Loss 0.0098\n",
            "Epoch 15 Batch 50 Loss 0.0098\n",
            "Epoch 15 Batch 60 Loss 0.0098\n",
            "Epoch 15 Batch 70 Loss 0.0098\n",
            "Epoch 15 Batch 80 Loss 0.0098\n",
            "Epoch 15 Batch 90 Loss 0.0098\n",
            "Epoch 15 Batch 100 Loss 0.0098\n",
            "Epoch 15 Batch 110 Loss 0.0098\n",
            "Epoch 15 Batch 120 Loss 0.0098\n",
            "Epoch 15 Batch 130 Loss 0.0097\n",
            "Epoch 15 Loss 0.0097\n",
            "Epoch 16 Batch 0 Loss 0.0097\n",
            "Epoch 16 Batch 10 Loss 0.0097\n",
            "Epoch 16 Batch 20 Loss 0.0097\n",
            "Epoch 16 Batch 30 Loss 0.0097\n",
            "Epoch 16 Batch 40 Loss 0.0096\n",
            "Epoch 16 Batch 50 Loss 0.0097\n",
            "Epoch 16 Batch 60 Loss 0.0096\n",
            "Epoch 16 Batch 70 Loss 0.0097\n",
            "Epoch 16 Batch 80 Loss 0.0097\n",
            "Epoch 16 Batch 90 Loss 0.0097\n",
            "Epoch 16 Batch 100 Loss 0.0097\n",
            "Epoch 16 Batch 110 Loss 0.0097\n",
            "Epoch 16 Batch 120 Loss 0.0097\n",
            "Epoch 16 Batch 130 Loss 0.0096\n",
            "Epoch 16 Loss 0.0096\n",
            "Epoch 17 Batch 0 Loss 0.0096\n",
            "Epoch 17 Batch 10 Loss 0.0096\n",
            "Epoch 17 Batch 20 Loss 0.0096\n",
            "Epoch 17 Batch 30 Loss 0.0096\n",
            "Epoch 17 Batch 40 Loss 0.0095\n",
            "Epoch 17 Batch 50 Loss 0.0096\n",
            "Epoch 17 Batch 60 Loss 0.0095\n",
            "Epoch 17 Batch 70 Loss 0.0095\n",
            "Epoch 17 Batch 80 Loss 0.0096\n",
            "Epoch 17 Batch 90 Loss 0.0096\n",
            "Epoch 17 Batch 100 Loss 0.0096\n",
            "Epoch 17 Batch 110 Loss 0.0096\n",
            "Epoch 17 Batch 120 Loss 0.0095\n",
            "Epoch 17 Batch 130 Loss 0.0095\n",
            "Epoch 17 Loss 0.0095\n",
            "Epoch 18 Batch 0 Loss 0.0095\n",
            "Epoch 18 Batch 10 Loss 0.0095\n",
            "Epoch 18 Batch 20 Loss 0.0095\n",
            "Epoch 18 Batch 30 Loss 0.0095\n",
            "Epoch 18 Batch 40 Loss 0.0094\n",
            "Epoch 18 Batch 50 Loss 0.0095\n",
            "Epoch 18 Batch 60 Loss 0.0094\n",
            "Epoch 18 Batch 70 Loss 0.0094\n",
            "Epoch 18 Batch 80 Loss 0.0095\n",
            "Epoch 18 Batch 90 Loss 0.0095\n",
            "Epoch 18 Batch 100 Loss 0.0095\n",
            "Epoch 18 Batch 110 Loss 0.0095\n",
            "Epoch 18 Batch 120 Loss 0.0094\n",
            "Epoch 18 Batch 130 Loss 0.0094\n",
            "Epoch 18 Loss 0.0094\n",
            "Epoch 19 Batch 0 Loss 0.0094\n",
            "Epoch 19 Batch 10 Loss 0.0094\n",
            "Epoch 19 Batch 20 Loss 0.0094\n",
            "Epoch 19 Batch 30 Loss 0.0094\n",
            "Epoch 19 Batch 40 Loss 0.0093\n",
            "Epoch 19 Batch 50 Loss 0.0094\n",
            "Epoch 19 Batch 60 Loss 0.0093\n",
            "Epoch 19 Batch 70 Loss 0.0094\n",
            "Epoch 19 Batch 80 Loss 0.0094\n",
            "Epoch 19 Batch 90 Loss 0.0094\n",
            "Epoch 19 Batch 100 Loss 0.0094\n",
            "Epoch 19 Batch 110 Loss 0.0094\n",
            "Epoch 19 Batch 120 Loss 0.0094\n",
            "Epoch 19 Batch 130 Loss 0.0093\n",
            "Epoch 19 Loss 0.0093\n",
            "Epoch 20 Batch 0 Loss 0.0093\n",
            "Epoch 20 Batch 10 Loss 0.0093\n",
            "Epoch 20 Batch 20 Loss 0.0093\n",
            "Epoch 20 Batch 30 Loss 0.0093\n",
            "Epoch 20 Batch 40 Loss 0.0093\n",
            "Epoch 20 Batch 50 Loss 0.0093\n",
            "Epoch 20 Batch 60 Loss 0.0093\n",
            "Epoch 20 Batch 70 Loss 0.0093\n",
            "Epoch 20 Batch 80 Loss 0.0093\n",
            "Epoch 20 Batch 90 Loss 0.0093\n",
            "Epoch 20 Batch 100 Loss 0.0093\n",
            "Epoch 20 Batch 110 Loss 0.0093\n",
            "Epoch 20 Batch 120 Loss 0.0093\n",
            "Epoch 20 Batch 130 Loss 0.0093\n",
            "Epoch 20 Loss 0.0093\n",
            "Total time: 15.65 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj86aiJL7Uy5",
        "outputId": "d0ad5f08-3294-4446-9417-f24b1f108471"
      },
      "source": [
        "# print(np.sum([np.prod(v.get_shape().as_list()) for v in sttn.trainable_variables]))\n",
        "sttn.load_weights('gdrive/MyDrive/trace/sttn-1')\n",
        "# err = 0.0\n",
        "# cnt = 0\n",
        "# for b in range(indf_test.shape[0]):\n",
        "#     inp = indf_test[b]\n",
        "#     tar = outdf_test[b]\n",
        "#     s_mask, t_mask = create_mask(inp)\n",
        "#     pred = sttn(inp, s_mask, t_mask)[0]\n",
        "#     cnt += 1\n",
        "#     err += loss_function(tar, pred, 'MAE')\n",
        "# print(err/cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd310351e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWkAgFAL8st9"
      },
      "source": [
        "real = np.array([0.0])\n",
        "predicted = np.array([0.0])\n",
        "for b in range(indf_test.shape[0]):\n",
        "    inp = indf_test[b]\n",
        "    tar = outdf_test[b]\n",
        "    s_mask, t_mask = create_mask(inp)\n",
        "    pred = sttn(inp, s_mask, t_mask)[0]\n",
        "    for i in range(B):\n",
        "        indices = np.array(tf.where(tar[i, :, T-1] != -1)[:, 0])\n",
        "        real = np.concatenate([real, tar[i, indices, T-1]])\n",
        "        predicted = np.concatenate([predicted, np.array(pred)[i, indices, 0]])\n",
        "real = real[1:]\n",
        "predicted = predicted[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "izjp1qw5DtUU",
        "outputId": "cc5cd11f-b3fc-488f-b7bb-7d6bd10cdf3f"
      },
      "source": [
        "plt.plot(np.arange(len(real)), real, 'red')\n",
        "plt.plot(np.arange(len(predicted)), predicted, 'blue')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}